{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.metrics\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (i).   Mapping labels to their resp. classes\n",
    "# (ii).  Mapping classes to their resp. labels\n",
    "\n",
    "label_to_class = {\n",
    "    1  : 'WALKING',          \n",
    "    2  : 'WALKING_UPSTAIRS', \n",
    "    3  : 'WALKING_DOWNSTAIRS',\n",
    "    4  : 'SITTING',      \n",
    "    5  : 'STANDING',       \n",
    "    6  : 'LAYING',         \n",
    "    7  : 'STAND_TO_SIT',      \n",
    "    8  : 'SIT_TO_STAND',     \n",
    "    9  : 'SIT_TO_LIE',     \n",
    "    10 : 'LIE_TO_SIT',      \n",
    "    11 : 'STAND_TO_LIE',      \n",
    "    12 : 'LIE_TO_STAND',   \n",
    "    np.nan : np.nan\n",
    "}\n",
    "class_to_label = {\n",
    "    'WALKING' : 1,\n",
    "    'WALKING_UPSTAIRS' : 2,\n",
    "    'WALKING_DOWNSTAIRS' : 3,\n",
    "    'SITTING' : 4,\n",
    "    'STANDING' : 5,         \n",
    "    'LAYING' : 6,      \n",
    "    'STAND_TO_SIT' : 7,     \n",
    "    'SIT_TO_STAND' : 8,     \n",
    "    'SIT_TO_LIE' : 9,     \n",
    "    'LIE_TO_SIT' : 10,        \n",
    "    'STAND_TO_LIE' : 11,     \n",
    "    'LIE_TO_STAND' : 12,\n",
    "    np.nan : np.nan\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to draw bar graph of classes corresponding to their frequencies in occurence\n",
    "\n",
    "def draw_bar(ydata):\n",
    "    print('Frequencies :- ',ydata.sum(axis = 0))\n",
    "    \n",
    "    x = np.arange(1,len(ydata[0])+1,1);\n",
    "    y = ydata.sum(axis = 0)\n",
    "    \n",
    "    plt.figure(figsize = (12.8,3))\n",
    "    plt.xlabel('Class Label',fontdict = {'size' : 15})\n",
    "    plt.ylabel('Frequency',fontdict = {'size' : 15})\n",
    "    bar = plt.bar(x,y)\n",
    "    \n",
    "    for idx,rect in enumerate(bar):\n",
    "        plt.text(\n",
    "            rect.get_x()+rect.get_width()/2.0,\n",
    "            rect.get_height(),int(y[idx]),\n",
    "            ha = 'center',\n",
    "            va = 'bottom'\n",
    "        )\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to draw xtrain time_series sensor data for first  instance of activity_label(class)\n",
    "# x == [ 0th milisecond data , 20th ms data , 40th ms, ...] for 50 Hz rate i.e. 20 ms for each timestamp \n",
    "# length = window_size\n",
    "# row stores the index of first data_point that belongs to class == activity_label \n",
    "\n",
    "def draw_wave(xdata,ydata,activity_label):\n",
    "    \n",
    "    row = 0\n",
    "    while(ydata[row].argmax()+1 != activity_label) : row = row + 1;\n",
    "    \n",
    "    length   = xdata.shape[1]\n",
    "    sensor   = xdata.shape[2]\n",
    "    channel  = xdata.shape[3]\n",
    "    \n",
    "    x = np.linspace(0,(20)*(length-1)/1000,length)\n",
    "    \n",
    "    plt.figure(figsize = (12.8,2))\n",
    "    plt.plot(x,xdata[row,:,0,0])\n",
    "    plt.plot(x,xdata[row,:,0,1])\n",
    "    plt.plot(x,xdata[row,:,0,2])\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize = (12.8,2))\n",
    "    plt.plot(x,xdata[row,:,1,0])\n",
    "    plt.plot(x,xdata[row,:,1,1])\n",
    "    plt.plot(x,xdata[row,:,1,2])\n",
    "    plt.xlabel('Time in seconds :- ( Instance of ' + label_to_class[activity_label] + ' data )',fontdict = {'size' : 15})\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (i).   Removing data-points where y and x values is null\n",
    "\n",
    "# Other methods can be\n",
    "# ffill (forward fill) => fills using forward points\n",
    "# bfill (backward fill) => using backward points\n",
    "# interpolate\n",
    "\n",
    "def remove_null(xdata,ydata):\n",
    "    xdata = xdata[np.where(np.isfinite(ydata))]\n",
    "    ydata = ydata[np.where(np.isfinite(ydata))]\n",
    "    ydata = ydata[np.where(np.isfinite(xdata).all(axis = 1).all(axis = 1).all(axis = 1))]\n",
    "    xdata = xdata[np.where(np.isfinite(xdata).all(axis = 1).all(axis = 1).all(axis = 1))]\n",
    " \n",
    "    return xdata,ydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize xdata using sklearn.preprocessing.StandardScaler and returns \n",
    "# scaler object to use it furthur for testing data\n",
    "\n",
    "# Each axis of each sensor has different min, max, I scaled according to them seperately\n",
    "# Initial shape == (None,128,2,3)\n",
    "# changed to (None , 6) :-\n",
    "# reshape to (None,128,6) -> swapaxis(0,2) -> reshape(6,-1) -> transpose\n",
    "# Fit scaler OR transform according to scaler\n",
    "\n",
    "# Reverse above process to get back oiginal data\n",
    "# transpose -> reshape(6,128,None) -> swapaxes(0,2) -> reshape(None,128,2,3)\n",
    "\n",
    "def get_scaler(xdata):\n",
    "    \n",
    "    row = xdata.shape[0]\n",
    "    timestamp = xdata.shape[1]\n",
    "    sensor = xdata.shape[2]\n",
    "    axis = xdata.shape[3]\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range = (-1,1))\n",
    "    xdata = xdata.reshape(row,timestamp,sensor*axis)\n",
    "    xdata = np.swapaxes(xdata,0,2).reshape(sensor*axis,-1).T\n",
    "    scaler.fit(xdata)\n",
    "    return scaler\n",
    "\n",
    "def scale_data(xdata,scaler):\n",
    "    \n",
    "    row = xdata.shape[0]\n",
    "    timestamp = xdata.shape[1]\n",
    "    sensor = xdata.shape[2]\n",
    "    axis = xdata.shape[3]\n",
    "    \n",
    "    xdata = xdata.reshape(row,timestamp,sensor*axis)\n",
    "    xdata = np.swapaxes(xdata,0,2).reshape(sensor*axis,-1).T\n",
    "    xdata = scaler.transform(xdata)\n",
    "    xdata = xdata.T.reshape(sensor*axis,timestamp,row)\n",
    "    xdata = np.swapaxes(xdata,0,2).reshape(row,timestamp,sensor,axis)\n",
    "    \n",
    "    return xdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in location, exp no., user no., start and end(end point is excluded from reading i.e lastpoint+1) point \n",
    "# ,overlap array, and returns xdata and ydata\n",
    "\n",
    "def create_windows(location, exp, user, start, end, activity, length, overlap):\n",
    "    \n",
    "    acc_file  = location + '/acc_exp'+ str(exp).zfill(2) + '_user' + str(user).zfill(2) + '.txt'\n",
    "    gyro_file = location + '/gyro_exp'+ str(exp).zfill(2) + '_user' + str(user).zfill(2) + '.txt'\n",
    "\n",
    "    acc_data  = np.loadtxt(acc_file)\n",
    "    gyro_data = np.loadtxt(gyro_file)\n",
    "    \n",
    "    xtrain = []\n",
    "    ytrain = []\n",
    "    \n",
    "    while (start + length <= end) : \n",
    "          \n",
    "        stop = start + length\n",
    "        window = []\n",
    "        \n",
    "        while start != stop :\n",
    "            window.append( [acc_data[start] , gyro_data[start]] )\n",
    "            start += 1\n",
    "        \n",
    "        xtrain.append(window)\n",
    "        ytrain.append(activity)\n",
    "        \n",
    "        start = stop - overlap[activity-1]\n",
    "\n",
    "    return xtrain,ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location == location of file\n",
    "# lenght == lenght of window\n",
    "# overlap == array of overlaps of size == number of unique activities\n",
    "# overlap depends on activity so as to extract more data from a particular class if needed\n",
    "\n",
    "\n",
    "# (i).   Loading labels.txt as labels\n",
    "# (ii).  Iterating in labels and calling create_windows on acceleration file, extending returned data in xtrain, ytrain \n",
    "# (iii). Iterating in labels and calling create_windows on gyroscope file, extending returned data in xtrain, ytrain \n",
    "\n",
    "def prepare_data(location,length = 128,overlap = [64]*12):\n",
    "\n",
    "    xdata = []\n",
    "    ydata = []\n",
    "        \n",
    "    labels = np.loadtxt(location+'/labels.txt',dtype = 'uint32')\n",
    "    \n",
    "    for exp,user,activity,start,end in labels :\n",
    "\n",
    "        xtemp , ytemp = create_windows(location, exp, user, start, end+1, activity, length, overlap)\n",
    "        xdata.extend(xtemp)\n",
    "        ydata.extend(ytemp)\n",
    "        \n",
    "    return np.array(xdata),np.array(ydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (i). Finds max element index sets its 1 and sets remaining 0\n",
    "#      for each row\n",
    "\n",
    "def to_categorical(ydata):\n",
    "    \n",
    "    for i in range(len(ydata)):\n",
    "        j = ydata[i].argmax()\n",
    "        for k in range(len(ydata[i])):\n",
    "            ydata[i][k] = (k == j)\n",
    "    return ydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (i).  OneHotEncoding ydata\n",
    "# (ii). Converting sparsh matrix ydata into dense form and then matrix into numpy array\n",
    "\n",
    "def one_hot_encoded(ydata):\n",
    "    ydata = OneHotEncoder().fit_transform(ydata.reshape(len(ydata),1))\n",
    "    ydata = np.asarray(ydata.todense())\n",
    "    return ydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing data, xtrain, ytrain\n",
    "# Last six classes [7 to 12] has very less weightage in data since they are extra classes added \n",
    "# , made from original six classes\n",
    "# so, I took more overlapping in them to get slightly more data\n",
    "\n",
    "xtrain, ytrain = prepare_data('/Users/huanjingheng/Downloads/FedCampus/HAPT/RawData', 128, [64,64,64,64,64,64,120,120,120,120,120,120])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,ytrain = remove_null(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into training (70%) testing (15%) and validation (15%) set\n",
    "\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(xtrain,ytrain,test_size = 0.3)\n",
    "xtest,xval,ytest,yval = train_test_split(xtest,ytest,test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9355, 128, 2, 3),\n",
       " (9355,),\n",
       " (2005, 128, 2, 3),\n",
       " (2005,),\n",
       " (2005, 128, 2, 3),\n",
       " (2005,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape,ytrain.shape,xtest.shape,ytest.shape,xval.shape,yval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (i).  Get scaler object\n",
    "# (ii). Scaling xtrain and xtest\n",
    "\n",
    "scaler = get_scaler(xtrain)\n",
    "xtrain = scale_data(xtrain,scaler)\n",
    "xtest  = scale_data(xtest,scaler)\n",
    "xval   = scale_data(xval,scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding y values\n",
    "\n",
    "ytrain = one_hot_encoded(ytrain)\n",
    "ytest = one_hot_encoded(ytest)\n",
    "yval = one_hot_encoded(yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9355, 128, 2, 3),\n",
       " (9355, 12),\n",
       " (2005, 128, 2, 3),\n",
       " (2005, 12),\n",
       " (2005, 128, 2, 3),\n",
       " (2005, 12))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape,ytrain.shape,xtest.shape,ytest.shape,xval.shape,yval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
